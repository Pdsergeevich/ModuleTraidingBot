"""
–ú–æ–¥—É–ª—å –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–π LLM —á–µ—Ä–µ–∑ Ollama
–ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ—Å–ø–ª–∞—Ç–Ω–æ –∏ –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
"""

import logging
import json
import re
import requests
from typing import Dict, Optional

from config import Config

logger = logging.getLogger(__name__)


class LocalAIAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –±–∞–∑–µ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM (Ollama)"""
    
    def __init__(self, model: str = "llama3.2:3b", ollama_url: str = "http://localhost:11434"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ò–ò-–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        
        Args:
            model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ Ollama (llama3.2:3b, mistral, deepseek-r1 –∏ —Ç.–¥.)
            ollama_url: URL Ollama API
        """
        self.model = model
        self.ollama_url = ollama_url
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama
        try:
            response = requests.get(f"{self.ollama_url}/api/tags")
            if response.status_code == 200:
                logger.info(f"‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–π –ò–ò-–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–º–æ–¥–µ–ª—å: {model})")
                logger.info("üí∞ –ë–ï–°–ü–õ–ê–¢–ù–´–ô —Ä–µ–∂–∏–º - –±–µ–∑ –ª–∏–º–∏—Ç–æ–≤ –∏ –ø–æ–¥–ø–∏—Å–æ–∫!")
            else:
                logger.warning(f"‚ö†Ô∏è Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: ollama serve")
        except Exception as e:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama: {e}")
            logger.info("üì• –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama: https://ollama.com/download")
    
    async def analyze_news(self, news_text: str, channel_name: str) -> Optional[Dict]:
        """
        –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–∏ —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π LLM
        
        Args:
            news_text: –¢–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏
            channel_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        logger.info(f"ü§ñ [LOCAL] –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ {channel_name}...")
        
        prompt = self._create_analysis_prompt(news_text)
        
        try:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ Ollama
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.3,
                        "num_predict": 500
                    }
                },
                timeout=60
            )
            
            if response.status_code != 200:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ Ollama API: {response.status_code}")
                return None
            
            result = response.json()
            ai_response = result.get('response', '')
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            analysis = self._parse_ai_response(ai_response)
            
            if analysis:
                logger.info(
                    f"‚úÖ [LOCAL] –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω:\n"
                    f"   –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {analysis['ticker']}\n"
                    f"   –ö–æ–Ω—Ç–µ–∫—Å—Ç: {analysis['context']}\n"
                    f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {analysis['confidence']:.2%}"
                )
            else:
                logger.info("‚ÑπÔ∏è [LOCAL] –ù–æ–≤–æ—Å—Ç—å –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞")
            
            return analysis
            
        except requests.exceptions.Timeout:
            logger.error("‚ùå –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ Ollama (–º–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç)")
            return None
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –Ω–æ–≤–æ—Å—Ç–∏: {e}")
            return None
    
    def _create_analysis_prompt(self, news_text: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π LLM"""
        return f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º —Ä—ã–Ω–∫–∞–º. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–æ–≤–æ—Å—Ç—å –∏ –æ–ø—Ä–µ–¥–µ–ª–∏:

1. –ö–û–ù–¢–ï–ö–°–¢ (–æ–¥–∏–Ω –∏–∑ —Ç—Ä–µ—Ö):
   - POSITIVE - –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å, —Ç–æ—Ä–≥–æ–≤–∞—Ç—å –≤ LONG (–ø–æ–∫—É–ø–∫–∞)
   - NEGATIVE - –Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å, —Ç–æ—Ä–≥–æ–≤–∞—Ç—å –≤ SHORT (–ø—Ä–æ–¥–∞–∂–∞)
   - NEUTRAL - –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å, —Ç–æ—Ä–≥–æ–≤–∞—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ

2. –¢–ò–ö–ï–† - —Ä–æ—Å—Å–∏–π—Å–∫–∏–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: SBER, GAZP, YNDX, LKOH, MOEX –∏ —Ç.–¥.

3. –£–í–ï–†–ï–ù–ù–û–°–¢–¨ - —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 1

4. –°–ò–õ–ê –í–õ–ò–Ø–ù–ò–Ø - LOW, MEDIUM –∏–ª–∏ HIGH

5. –û–ë–™–Ø–°–ù–ï–ù–ò–ï - –∫—Ä–∞—Ç–∫–∞—è –ø—Ä–∏—á–∏–Ω–∞

–ù–æ–≤–æ—Å—Ç—å: "{news_text}"

–û—Ç–≤–µ—Ç—å –°–¢–†–û–ì–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
{{
    "ticker": "SBER",
    "context": "POSITIVE",
    "confidence": 0.85,
    "expected_impact": "HIGH",
    "reasoning": "–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ"
}}

–ï—Å–ª–∏ –Ω–æ–≤–æ—Å—Ç—å –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ç–æ—Ä–≥–æ–≤–ª–µ, –≤–µ—Ä–Ω–∏:
{{
    "ticker": null,
    "context": "NEUTRAL",
    "confidence": 0,
    "expected_impact": "LOW",
    "reasoning": "–Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞"
}}"""
    
    def _parse_ai_response(self, response: str) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ AIAnalyzer)"""
        try:
            # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
            json_match = re.search(r'\{[^{}]*\}', response, re.DOTALL)
            if not json_match:
                logger.warning("‚ö†Ô∏è JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM")
                return None
            
            analysis = json.loads(json_match.group())
            
            if not analysis.get('ticker'):
                return None
            
            if analysis['confidence'] < Config.MIN_AI_CONFIDENCE:
                logger.info(
                    f"‚ö†Ô∏è –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è: "
                    f"{analysis['confidence']:.2%}"
                )
                return None
            
            context = analysis['context'].upper()
            if context not in ['POSITIVE', 'NEGATIVE', 'NEUTRAL']:
                return None
            
            direction_map = {
                'POSITIVE': 'UP',
                'NEGATIVE': 'DOWN',
                'NEUTRAL': 'NEUTRAL'
            }
            
            return {
                'ticker': analysis['ticker'].upper(),
                'context': context,
                'direction': direction_map[context],
                'confidence': float(analysis['confidence']),
                'expected_impact': analysis.get('expected_impact', 'MEDIUM'),
                'reasoning': analysis.get('reasoning', '')
            }
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            return None
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return None


if __name__ == '__main__':
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    import asyncio
    
    logging.basicConfig(level=logging.INFO)
    
    async def test():
        analyzer = LocalAIAnalyzer(model="llama3.2:3b")
        
        test_news = "–°–±–µ—Ä–±–∞–Ω–∫ –æ–±—ä—è–≤–∏–ª –æ —Ä–µ–∫–æ—Ä–¥–Ω–æ–π –∫–≤–∞—Ä—Ç–∞–ª—å–Ω–æ–π –ø—Ä–∏–±—ã–ª–∏, –ø—Ä–µ–≤—ã—Å–∏–≤—à–µ–π –æ–∂–∏–¥–∞–Ω–∏—è –Ω–∞ 15%"
        
        result = await analyzer.analyze_news(test_news, "Test")
        print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
    
    asyncio.run(test())
